{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anacondanew\\lib\\site-packages (4.13.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anacondanew\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anacondanew\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "   !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "first get the webpage https://www.shine.com/\n",
    "Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering Designation in search box-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"form-control       \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering Designation in search box-\n",
    "designation_analyst = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/ul/li[4]\")\n",
    "designation_analyst.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering Location in search box-\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Search Button-\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List for different attributes-\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for different Attributes-\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')  \n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)   \n",
    "    \n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')  \n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking length for all attributes-\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>krishna consultancy.. hiring for co...</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Entry Operator(data analyst work) REMOTE ...</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>prime services..</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>harjai computers private limited</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>true caller</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mobility Data Analyst - IN/MKR</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>true caller</td>\n",
       "      <td>5 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hiring for data entry analyst ( position data ...</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>prime services..</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hiring for data entry analyst work</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>realtech solutions</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hiring for data entry analyst ( position data ...</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>realtech solutions</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles       Location  \\\n",
       "0                             Technical Data Analyst  Bangalore\\n+9   \n",
       "1  Data Entry Operator(data analyst work) REMOTE ...  Bangalore\\n+9   \n",
       "2                            Hiring For Data Analyst  Bangalore\\n+8   \n",
       "3                                Senior Data Analyst  Bangalore\\n+8   \n",
       "4                                       Data Analyst      Bangalore   \n",
       "5                     Mobility Data Analyst - IN/MKR      Bangalore   \n",
       "6                                Senior Data Analyst      Bangalore   \n",
       "7  hiring for data entry analyst ( position data ...  Bangalore\\n+9   \n",
       "8                 hiring for data entry analyst work  Bangalore\\n+9   \n",
       "9  hiring for data entry analyst ( position data ...  Bangalore\\n+9   \n",
       "\n",
       "                                  Company  Experience  \n",
       "0  krishna consultancy.. hiring for co...  4 to 9 Yrs  \n",
       "1                        prime services..   0 to 1 Yr  \n",
       "2        harjai computers private limited  2 to 5 Yrs  \n",
       "3        harjai computers private limited  0 to 2 Yrs  \n",
       "4                             true caller  3 to 5 Yrs  \n",
       "5                             bosch group  4 to 6 Yrs  \n",
       "6                             true caller  5 to 7 Yrs  \n",
       "7                        prime services..   0 to 1 Yr  \n",
       "8                      realtech solutions   0 to 1 Yr  \n",
       "9                      realtech solutions   0 to 1 Yr  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe-\n",
    "df = pd.DataFrame({'Titles':job_title,'Location':job_location,'Company':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "Then click the search button.\n",
    "Then apply the location filter and salary filter by checking the respective boxes\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering Designation in search box-\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "#Clicking on Search Button-\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "# Setting the location filter-\n",
    "location_delhi=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "location_delhi.click()\n",
    "\n",
    "# Setting the Salary filter-\n",
    "salary_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List for different attributes-\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_Reqd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for different Attributes from different pages-\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    title=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "    for i in title[0:10]:\n",
    "        job_title.append(i.text)\n",
    "    location=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    for i in location[0:10]:\n",
    "        job_location.append(i.text)    \n",
    "    company=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    for i in company[0:10]:\n",
    "        company_name.append(i.text)\n",
    "    experience=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "    for i in experience[0:10]:\n",
    "        exp_Reqd.append(i.text)       \n",
    "    next_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking length for all attributes-\n",
    "print(len(job_title),len(job_location),len(company_name),len(exp_Reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>Delhi / NCR(Vaishali)</td>\n",
       "      <td>Kreate Energy</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job_title  \\\n",
       "0            Data Scientist - Noida/Bangalore   \n",
       "1             DigitalBCG GAMMA Data Scientist   \n",
       "2             Senior Associate - Data Science   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5              Data Scientist - MIND Infotech   \n",
       "6           Data Scientist - Engine Algorithm   \n",
       "7                      Data Science Associate   \n",
       "8                              Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                         Noida, Bangalore/Bengaluru   \n",
       "1                     New Delhi, Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5                                              Noida   \n",
       "6  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "7                              Delhi / NCR(Vaishali)   \n",
       "8             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_name Experience  \n",
       "0                                       EXL   5-10 Yrs  \n",
       "1                   Boston Consulting Group    2-5 Yrs  \n",
       "2                              Black Turtle    4-7 Yrs  \n",
       "3                  SECUREKLOUD TECHNOLOGIES    2-7 Yrs  \n",
       "4                  SECUREKLOUD TECHNOLOGIES    2-7 Yrs  \n",
       "5  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs  \n",
       "6                              Primo Hiring    1-3 Yrs  \n",
       "7                             Kreate Energy    2-4 Yrs  \n",
       "8   Mount Talent Consulting Private Limited    2-4 Yrs  \n",
       "9   Mount Talent Consulting Private Limited    2-4 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experience':exp_Reqd})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART.\n",
    "you have to scrape the below mention attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "- You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking length for all attributes-\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(stars),len(short_review),len(complete_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Its good.. a little heavy on my pinky but its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Worth the money’ starting first from its perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>Worst product delivered by Flipkart\\nAfter 10d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       4      Value-for-money   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5            Wonderful   \n",
       "96      5             Terrific   \n",
       "97      5  Best in the market!   \n",
       "98      5     Perfect product!   \n",
       "99      1    Absolute rubbish!   \n",
       "\n",
       "                                         Full_summary  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Its good.. a little heavy on my pinky but its ...  \n",
       "96  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "97  Damn this phone is a blast . Upgraded from and...  \n",
       "98  Worth the money’ starting first from its perfo...  \n",
       "99  Worst product delivered by Flipkart\\nAfter 10d...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rating':stars,'Review_summary':short_review,'Full_summary':complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 3 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "-  Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering sneakers in search box-\n",
    "sneakers=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "sneakers.send_keys('sneakers')\n",
    "\n",
    "pop_up=driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "#Clicking on Search Button-\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List for different attributes-\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for different Attributes-\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements(By.CLASS_NAME,'_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 160 160\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 3 Latest Casual Shoes Sneakers F...</td>\n",
       "      <td>₹557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Footox</td>\n",
       "      <td>Walking Shoes for Men | Running Shoes | Casual...</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>₹282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Comfy Mid-Top Casual Chunky Streetwear Fashion...</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Cross Trainer Mid-Top Sporty Chunky Sneakers f...</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>MAPF1 X-Ray Speed Sneakers For Men</td>\n",
       "      <td>₹4,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Go Run Fast - Sneakers For Women</td>\n",
       "      <td>₹2,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Skipper Sneakers For Men</td>\n",
       "      <td>₹1,799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                          Prod_desc   Price\n",
       "0         BRUTON  Combo Pack Of 3 Latest Casual Shoes Sneakers F...    ₹557\n",
       "1         Footox  Walking Shoes for Men | Running Shoes | Casual...    ₹699\n",
       "2           aadi  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...    ₹282\n",
       "3           aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ₹434\n",
       "4         Kzaara                                   Sneakers For Men    ₹219\n",
       "..           ...                                                ...     ...\n",
       "155  bacca bucci  Comfy Mid-Top Casual Chunky Streetwear Fashion...  ₹1,599\n",
       "156  bacca bucci  Cross Trainer Mid-Top Sporty Chunky Sneakers f...  ₹1,599\n",
       "157         PUMA                 MAPF1 X-Ray Speed Sneakers For Men  ₹4,799\n",
       "158     Skechers                   Go Run Fast - Sneakers For Women  ₹2,199\n",
       "159         PUMA                           Skipper Sneakers For Men  ₹1,799\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe-\n",
    "df=pd.DataFrame({'Brand':brand,'Prod_desc':description,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7”\n",
    "After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price# 8)Amazon Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering laptop in search box-\n",
    "laptop=driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']//input\")\n",
    "laptop.send_keys('Laptop')\n",
    "\n",
    "#Clicking on Search Button-\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to filter i7 CPu-\n",
    "cpu_filter1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[6]/li[12]/span/a/div/label/i\")\n",
    "cpu_filter1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List for different attributes-\n",
    "Title=[]\n",
    "price=[]\n",
    "Ratings=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    title=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "    for i in title[0:10]:\n",
    "        Title.append(i.text) \n",
    "    prices=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "    for i in prices[0:10]:\n",
    "        price.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_rat=driver.find_elements(By.XPATH,\"//div[@class='a-row a-size-small']/span\")\n",
    "for i in titles_rat:\n",
    "    Rating.append(i.get_attribute(\"aria-label\"))\n",
    "rating=[]\n",
    "for i in range(0,len(Rating))[0:20]:\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        rating.append(Rating[i][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking length for all attributes-\n",
    "print(len(Title),len(price),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ZenBook Duo 14 (2021) Dual Screen Laptop,...</td>\n",
       "      <td>1,47,349</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>94,990</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...</td>\n",
       "      <td>49,990</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>79,990</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>99,990</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td>74,990</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 5320 Laptop, i7-1260P, 16GB LPDD...</td>\n",
       "      <td>84,918</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>1,44,990</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop Intel core i7 11th ...</td>\n",
       "      <td>78,990</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>92,528</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price Ratings\n",
       "0  ASUS ZenBook Duo 14 (2021) Dual Screen Laptop,...  1,47,349     3.8\n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...    94,990     4.3\n",
       "2  ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...    49,990     4.2\n",
       "3  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...    79,990     4.1\n",
       "4  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...    99,990     4.0\n",
       "5  Samsung Galaxy Book2 (NP750) Intel 12th Gen co...    74,990     3.7\n",
       "6  Dell Inspiron 5320 Laptop, i7-1260P, 16GB LPDD...    84,918     5.0\n",
       "7  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...  1,44,990     4.2\n",
       "8  Acer Nitro 5 Gaming Laptop Intel core i7 11th ...    78,990     4.0\n",
       "9  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    92,528     4.3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe-\n",
    "df=pd.DataFrame({'Title':Title,'Price':price,'Ratings':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap Top 1000 Quotes Of All Time\n",
    "This task will be done in following steps:<br>\n",
    "1.First get the webpage https://www.azquotes.com/<br>\n",
    "2. Click on Top Quotes<br>\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage-\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Top Quotes\n",
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details\n",
    "\n",
    "Quote=[]\n",
    "Author=[]\n",
    "type_of_quote=[]\n",
    "\n",
    "Details=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,\"//div[@class='wrap-block']\")]\n",
    "\n",
    "for i in Details:\n",
    "    Quote.append(i[0])\n",
    "    Author.append(i[1])\n",
    "    type_of_quote.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quotes                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                               Type of quote  \n",
       "0   Essence, Deep Thought, Transcendentalism  \n",
       "1                  Inspiration, Past, Trying  \n",
       "2                        Country, Peace, War  \n",
       "3         Inspirational, Motivational, Death  \n",
       "4               4th Of July, Food, Patriotic  \n",
       "..                                       ...  \n",
       "95                    Music, Sports, Hunting  \n",
       "96             Trust, Encouraging, Uplifting  \n",
       "97              Inspirational, Funny, Change  \n",
       "98                      Success, God, Mother  \n",
       "99       Inspirational, Motivational, Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({'Quotes':Quote,'Author':Author,'Type of quote':type_of_quote })\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
